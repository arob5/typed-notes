\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\def\R{\mathbb{R}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}} % For lines in matrix to represent columns
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}} % For lines in matrix to represent rows

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{notation}{Notation}

\begin{document}

\begin{center}
\Large
Hierarchical Models
\end{center}

\begin{flushright}
Andrew Roberts
\end{flushright} 

% Section: Motivation
\section{Motivation}

\subsection{Accounting for Correlation}
The primary motivation for utilizing multilevel and hierarchical structures in regression modeling is to account for correlation structures that are ignored in the standard linear model and generalized 
linear model (GLM) framework. Indeed, consider the standard linear model setup 
\[y_i|x_i \overset{ind}{\sim} N(x_i^T \beta, \sigma^2)\]
In words, we're assuming that once we fix a value of $x_i$ then we can treat all of the observations at that fixed value as essentially identical; that is, their response values $y_i$ are independent 
and vary based on the same Gaussian noise structure. For example, if $x_i$ is just an indicator for age then we treat the outcomes of everybody of the same age as independent. This might be inadequate. 
For example, what if gender has a large effect on $y$, such that the response values tend to cluster together based on gender. In this case, the values $y_i|x_i$ are certainly not independent, so the assumptions
of the model have been violated. Obviously, the solution here would be to add a second predictor corresponding to gender. However, there are often other sources of variation still not accounted for. It can be very 
difficult to account for all of these sources of variation, so trying to do so simply by adding more predictors to the linear model is oftentimes infeasible. These sources of variation can arise out of 
group-like structure in the data, a classic example being that of modeling student grades. In this case we expect individual-level predictors (e.g. student aptitude) to affect grades, but we also 
expect there to be some sort of school effect (e.g. quality of teachers in a school). This sort of clustering can create correlation structures not accounted for in the basic regression model.  

One method to account for these issues is to explicitly model the 
correlation structure of the data. However, it is often very difficult to develop a good parametric model for the correlation. Hierarchical models provide an alternative approach. The following section
offers an introduction to hierarchical models through a specific example. 

\subsection{Example}
As a motivating example, I consider the analysis of child support enforcement discussed in Gelman and Hill (2009, ch. 11). The outcome of interest here is a binary indicator of whether a father provided child
support payments (as self-reported by the mother). The sampled families live in a variety of cities, and the main treatment of interest here is a measure of the level of enforcement conducted by the city. I will 
consider the following additional covariates (the model in Gelman and Hill, 2009 includes additional ones as well): the age of the father (individual-level) and a measure of the benefits provided by the city to 
the mother (city-level). As I have made very explicit here, this problem has a natural hierarchical structure; some variables pertain to individuals while others to cities. To build up to hierarchical models, we will
consider a sequence of different models, focusing on the assumptions that models make about the correlation structure of the underlying data.

\subsubsection{Notation}
Let $(y_i, x_i)$, $i = 1, \dots, n$ denote the full pooled dataset, where $y_i \in \{0, 1\}$ is an indicator of whether father $i$ provided the payments. Here $x_i$ is a vector that includes the covariates described above as well as city-level indicators. We will also find it useful to partition these predictors as $x_i = (x_i^{\text{indiv}}, x_i^{\text{city}}, \text{city}_i)$, where $x_i^{\text{indiv}}$ contains the individual-level predictors (father age), $x_i^{\text{city}}$ contains the city-level predictors (enforcement level, benefit level), and $\text{city}_i$ represents the set of city indicators. Note that in this pooled dataset the values
of the city-level predictors will be repeated for all individuals within the same city. From the standpoint of computer memory, this would be a pretty inefficient way of storing this data. 

\subsubsection{Basic Pooled Regression}
We start by considering a basic logit model on this pooled dataset, regressing on just the individual-level predictors. 
\[y_i|x_i^{\text{indiv}} \overset{ind}{\sim} \text{Bern}(\text{logit}^{-1}(\beta^T x_i^{\text{indiv}})) \]
This model assumes that the probability of a father providing child support payments is independent across cities given the individual-level covariates; in other words, this model treats all cities as identical. 
This is probably not a realistic model, as we expect local city laws and policy to influence this probability. If we also included the city-level covariates (but not the city indicators) as independent variables in the above regression, then the city-level variables would essentially just be treated as individual-level predictors that happen to be constant for individuals within a fixed city. 

\subsubsection{Adding City Indicators}
The classical regression way to account for city variation is to simply add indicator variables for each city. 
\[y_i|x_i \overset{ind}{\sim} \text{Bern}(\text{logit}^{-1}(x_i^T \beta)) \]
where $x_i$ includes the covariates described above as well as city-level indicators. Another way to describe this model is a set of \textit{parallel regressions}; we can think of estimating a regression 
separately for each city, where the slope coefficients are constant across cities (hence, parallel) but the intercepts vary by city. Note that the classical regression setup would also allow us to vary the 
slope coefficients for each city, by including interactions between the city indicators and the other predictors. However, in this example let's suppose that we think the constant slope coefficients are a good 
modeling choice; we instead focus on the varying intercept terms. 

Why might the regression independence assumption be an issue here? Well, the model assumes that the probability of a father providing 
child support is independent within a fixed city and given father age, a fixed city benefit level, and a fixed city enforcement level. However, there are almost certainly other city-level variation that this model 
does not account for. Consider fixing the values of the individual and city-level covariates. This model assumes that the observations are independent once we also fix a given city; moreover, the error structure
does not depend on which city we fix. If we were estimating a linear model, then this assumption would take the form of a fixed variance $\sigma^2$ for the observed outcomes across all cities, conditional 
on the other covariates. However, we might imagine there are unobserved city-specific factors that might affect this variance. We now see the downside of including the city-level information in the individual-level 
regression; it forces us to impose strict assumptions on city-level variation that don't seem very plausible. What we'd really like is a model that treats the individual-level and city-level variation separately. 

One option is to drop the conditional independence assumption and assume some model for the correlation structure; for example, we might suppose that the observations are correlated within cities but independent
across cities. This would essentially allow us to model a different variance for each city, addressing the limitation mentioned above. However, choosing a specific correlation model is still imposing quite rigid assumptions
that are not likely to be satisfied in practice. Alternative ideas to addressing this problem are explored below. 

\subsubsection{Two-Stage Regression}
Noting the desire to capture individual and city-level variation separately, we might try estimating two separate regressions: an individual-level regression and a city-level regression. This gives the flexibility
of assuming distinct error structures on the individual and city levels. The idea here is to first estimate the city intercepts using only individual-level data 
\begin{enumerate}
\item First estimate the logit model using only the individual predictors and the city indicators. Here, $\beta = (\beta^{\text{indiv}}, \beta^{\text{city}})$ contains the regression coefficients for the individual-level 
predictors, as well as one coefficient per city, and therefore does not include an intercept term. 
\[y_i|x_i^{\text{indiv}}, \text{city}_i \overset{ind}{\sim} \text{Bern}(\text{logit}^{-1}([x_i^{\text{indiv}}, \text{city}_i]^T \beta)) \]
\item Treating the estimated regression city coefficients $\hat{\beta}^{\text{city}}_1, \dots, \hat{\beta}^{\text{city}}_J$ (supposing there are $J$ cities) as the response variable, fit a linear model by regressing on the 
city-level predictors. 
\[\hat{\beta}^{\text{city}}_j|x_j^{\text{city}} \overset{ind}{\sim} N([x_j^{\text{city}}]^T \gamma, \sigma^2)\]
\end{enumerate}
The first regression can be interpreted as allowing each city to have its own intercept, but ignores any city-level variation beyond these simple indicators. The second regression considers the linear effect of 
the city-level covariates (city enforcement, city benefits) on the estimated city intercepts (in logit-space). A larger value of $\hat{\beta}^{\text{city}}_j$ indicates that fathers from city $j$ are more likely to provide child support, on average. A larger value of $\hat{\gamma}_{\text{enforcement}}$ indicates that cities with higher enforcement levels tend to have larger estimated city intercepts, on average. 


% Resources
\section{Resources}
\begin{itemize}
\item Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2009)
\end{itemize}






\end{document}

