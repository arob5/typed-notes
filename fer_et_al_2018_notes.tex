\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\def\R{\mathbb{R}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}} % For lines in matrix to represent columns
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}} % For lines in matrix to represent rows

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{notation}{Notation}

\begin{document}

\begin{center}
\Large
Notes on Bayesian emulation procedure described in Fer et al 2018
\end{center}

\begin{flushright}
Andrew Roberts
\end{flushright} 

% General Notes
\section{General Notes}
To simplify the model in order to understand it piece by piece I am currently making the following simplifying assumptions: 
\begin{enumerate}
\item Only considering one site, and thus neglecting the hierarchical model across different sites. 
\item Only considering a single simulator output; that is, supposing the simulator is a scalar-valued function.
\item Considering direct emulation of the model outputs, rather than the sufficient statistics.  
\end{enumerate}
I will add in these complexities to these notes once I am certain I fully understand the simpler model. 

% Goals
\section{Goals}
\begin{itemize}
\item Calibrate parameters of (deterministic) computer simulator to real-world data
\item Limited computationally so can only run full simulation at a limited number of points in parameter space; hence also interested in interpolating between the 
outputs observed outputs at these points and quantifying the interpolation uncertainty
\end{itemize}

% Notation and Setup
\section{Notation and Setup}
Let $\mathcal{P} \subset \R^d$ be the parameter space (meaning the set of possible simulation parameters). Denote the deterministic simulator by the function $f: \mathcal{P} \to \R$, 
where for simplicity I'm assuming only a single scalar output for now. Moreover, I assume that the parameter space is composed of two types of parameters: \textit{observation}
and \textit{calibration} parameters. The former refers to parameters we can observe in the real-world that can also be included in the computer model. The latter refers
to parameters of the simulator that are not directly observable in the real-world; these may be purely computational tuning parameters, but they can also have physical meaning. 
We thus assume $\mathcal{P} = \mathcal{X} \times \mathcal{U}$ where $\mathcal{X} \in \R^{d_1}$ and $\mathcal{U} \in \R^{d_2}$ are the spaces of observation and calibration
parameters, respectively. 

For a given parameter value $(x_i, u_i) \in \mathcal{P}$ I denote the simulation output by $y_i = f(x_i, u_i)$.
The observation parameters $x$ are thought of like covariates in a typical regression model, while $u$ garners our attention as the main parameters of interest. Instead of supposing 
there is some ``best'' parameter vector $u$, we instead adopt a Bayesian approach and treat $u$ as random. 
 We thus assume a prior distribution $\pi_0$ over $\mathcal{U}$. 
With the goal of parameter calibration in mind, we assume that we observe some real-world outputs $z = (z_1, \dots, z_n)$, observed at observation parameter values 
$x = (x_1, \dots, x_n)$. A simple model might assume that the real-world output data is random, but that the simulated outputs give the mean of the observed data. 
For concreteness, I'll just consider the following hierarchical Gaussian noise model. Letting $y = (f(x_1, u), \dots, f(x_n, u))$,
\begin{align*}
&z|x, u, \tau \sim N_n(y, \tau^2 I_n) \\
&\tau|x, u \sim p_0 \\
&u|x \sim \pi_0
\end{align*}

We are ultimately interested in the posterior over both the calibration and statistical parameters $p(u, \tau|\mathcal{D}_z)$, where $\mathcal{D}_z = \{(x_1, z_1), \dots, (x_n, z_n)\}$.  

% Brute-Force Approach
\section{Brute-Force Approach}
Fer et al contrast their Bayesian emulation approach with what they call a ``brute-force'' approach. I believe this is just the straightforward approach of using MCMC to sample from 
\[p(u, \tau|\mathcal{D}_z) \propto p(z|x, u, \tau)p(u, \tau) = N_n(z|f(x, u), \tau^2 I_n)p_0(\tau|x, u)\pi_0(u|x)\] 
The key observation is that the likelihood depends on $f(x, u)$ so at each step $t$ of MCMC the full simulation must be run on the current proposed parameter value $u^{(t)}$. This is costly considering this is not parallelizable. This procedure may be appropriate in the case that the simulation model is very cheap to run, but for complex models this is not 
feasible. 

% GP Emulator Approach
\section{GP Emulator Approach}
To prevent having to perform full simulation runs at each iteration, we consider a GP emulator for $f$. We choose a set of parameter values (i.e. \textit{design points} or \textit{knots}) $x_1, \dots, x_n \in \mathcal{P}$ at which to run the full simulation, yielding the observed simulator outputs $y_1, \dots, y_n$. This step can be done in parallel, 
thus saving computational time. The idea is now to consider the simulator output as random; even though we could technically run the simulator at any parameter value, the 
computational burden renders this infeasible and it is therefore reasonable to treat the outputs are unknown and random. 

I'll consider a GP of the form 
\[\eta(\cdot)|\beta, \sigma \sim \mathcal{GP}(m_\beta(\cdot), k_\sigma(\cdot, \cdot))\]
with mean function and kernel given by 
\begin{align*}
m_\beta(x) &= \phi(x)^T \beta \\
k_{\sigma}(x, x^\prime) &= \sigma^2 c(x, x^\prime)
\end{align*}
where $\phi: \mathcal{P} \to \R^q$ is some feature mapping and $c(\cdot, \cdot)$ is a valid correlation function. I'll denote by $Y_i$ the random output of the GP evaluated at the design point $x_i$. 

\end{document}


