\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\def\R{\mathbb{R}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}} % For lines in matrix to represent columns
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}} % For lines in matrix to represent rows

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{notation}{Notation}

\begin{document}

\begin{center}
\Large
Notes on Bayesian emulation procedure described in Fer et al 2018
\end{center}

\begin{flushright}
Andrew Roberts
\end{flushright} 

% General Notes
\section{General Notes}
To simplify the model in order to understand it piece by piece I am currently making the following simplifying assumptions: 
\begin{enumerate}
\item Only considering one site, and thus neglecting the hierarchical model across different sites. 
\item Only considering a single simulator output; that is, supposing the simulator is a scalar-valued function. 
\end{enumerate}
I will add in these complexities to these notes once I am certain I fully understand the simpler model. 

% Goals
\section{Goals}
\begin{itemize}
\item Calibrate parameters of (deterministic) computer simulator to real-world data
\item Limited computationally so can only run full simulation at a limited number of points in parameter space; hence also interested in interpolating between the 
outputs observed outputs at these points and quantifying the interpolation uncertainty
\end{itemize}

% My Notation
\section{My Notation}
Let $\mathcal{P} \subset \R^d$ be the parameter space (meaning the set of possible simulation parameters). Denote the deterministic simulator by the function $f: \mathcal{P} \to \R$, 
where for simplicity I'm assuming only a single scalar output for now. For a given parameter value $x_i \in \mathcal{P}$ I denote the simulation output by $y_i = f(x_i)$.
 We assume a prior distribution $\pi_0$ over $\mathcal{P}$; looks like they assume a non-informative prior in the paper. 
With the goal of parameter calibration in mind, we assume that we observe some real-world data $z = (z_1, \dots, z_N)$, which is characterized by some assumed error model that depends on the simulator parameter
$x$. For concreteness, I'll just consider the following Gaussian noise model. 
\begin{align*}
&z_i|x, \tau \overset{ind}{\sim} N(f(x), \tau^2), \qquad i = 1, \dots, N \\
&\tau|x \sim p_0 \\
&x \sim \pi_0
\end{align*}
I guess I am implicitly assuming here that the simulation parameters $x$ have some sort of real physical meaning, given that I'm modeling the real-world data $z_i$ conditional on $x$. 
I'm considering something like $x$ including some site-specific property of the soil, for instance. When running the simulation at a specific site, we don't know the correct setting for this soil 
property, but we observe outputs $z$ that give us information about the property, and moreover the simulation $f$ is parameterized by this property. We are ultimately interested in the 
posterior over both the calibration and statistical parameters $p(x, \tau|z)$. 

% Brute-Force Approach
\section{Brute-Force Approach}
Fer et al contrast their Bayesian emulation approach with what they call a ``brute-force'' approach. I believe this is just the straightforward approach of using MCMC to sample from 
$p(x, \tau|z) \propto p(z|x, \tau)p(x, \tau) = N(z|f(x), \tau^2)p_0(\tau|x)\pi_0(x)$. 
The key observation is that the likelihood depends on $f(x)$ so at each step of MCMC the full simulation must be run on the current proposed parameter value $x$. This is costly considering 
this is not parallelizable. 

% GP Emulator Approach
\section{GP Emulator Approach}
To prevent having to perform full simulation runs at each iteration, we consider a GP emulator for $f$. We choose a set of parameter values (i.e. \textit{design points} or \textit{knots}) $x_1, \dots, x_n \in \mathcal{P}$ at which to run the full simulation, yielding the observed simulator outputs $y_1, \dots, y_n$. This step can be done in parallel. I'll consider a GP of the form 
\[\eta(\cdot)|\beta, \sigma \sim \mathcal{GP}(m_\beta(\cdot), k_\sigma(\cdot, \cdot))\]
with mean function and kernel given by 
\begin{align*}
m_\beta(x) &= \phi(x)^T \beta \\
k_{\sigma}(x, x^\prime) &= \sigma^2 c(x, x^\prime)
\end{align*}
where $\phi: \mathcal{P} \to \R^q$ is some feature mapping and $c(\cdot, \cdot)$ is a valid correlation function. I'll denote by $Y_i$ the random output of the GP evaluated at the design point $x_i$. 

\end{document}


