\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Data Assimilation: Filtering and Smoothing}
\author{Andrew Roberts}

\begin{document}

\maketitle
\tableofcontents
\newpage

% General Framework
\section{The General Framework}

\subsection{The Stochastic Dynamics Model}
We consider the following stochastic dynamics model. 
\begin{align}
&x_{t + 1} = g(x_t) + \xi_t, && \xi_t \overset{iid}{\sim} \mathcal{N}(0, \Sigma_x) \label{stochastic_dynamics_model} \\
&y_{t + 1} = h(x_{t+1}) + \epsilon_{t+1}, && \epsilon_t \overset{iid}{\sim} \mathcal{N}(0, \Sigma_\epsilon) \nonumber 
\end{align}
The first line describes a stochastic Markov dynamical system, while the second defines an observation model. Moreover, we assume a random initial condition 
\[x_0 \sim \mathcal{N}(\mu_0, \Sigma_0)\]
where $\Sigma_0$ is positive definite and assume independence $x_0 \perp \{\xi_t\} \perp \{\epsilon_t\}$. 
We suppose the states $x_t$ and observations $y_t$ are $P$ and $N$-dimensional vectors, respectively. 
In large-scale settings, the case $D > N$ is quite common, as the state vector may be derived, for example, from a fine discretization of space. 

\subsection{Filtering and Smoothing}
I will follow Stuart et al's notation and denote $Y_t := \{y_1, y_2, \dots, y_t\}$. Given this notation, the \textit{filtering problem} is concerned with characterizing the following distribution:
\[\pi_{t}(x_t) := p(x_t|Y_t)\]
That is, the distribution of the current state given observations up through the current time. The primary goal of the filtering problem is to iteratively update the filtering distribution $\pi_t$ in 
an efficient manner as new data arrives. When a new observation $y_{t + 1}$ arrives, we can think of this update as consisting of two steps. 
\begin{enumerate}
\item \textbf{Prediction:} Iterate the dynamical model one time step forward to obtain the predictive distribution $\hat{\pi}_{t+1}(x_{t+1}) := p(x_{t+1}|Y_t)$. We can think of this as applying 
an operator $\mathcal{P}$ which transforms the current filtering distribution into the predictive distribution: $\hat{\pi}_{t+1} = \mathcal{P}\pi_t$. 
\item \textbf{Analysis:} Incorporate the new observation $y_{t+1}$ via Bayes' rule to obtain the new filtering distribution $\pi_{t+1}(x_{t+1})$. This can be thought of again as 
applying a map $\mathcal{A}_t$ (which in this case depends on $t$, since it depends on the data), so that $\pi_{t + 1} = \mathcal{A}_t \hat{\pi}_{t+1}$. 
\end{enumerate}
Putting these together, the main goal of filtering is to characterize the updated distribution 
\[\pi_{t + 1} = \mathcal{A}_t \mathcal{P} \pi_t \]

We now derive the form taken by the two operators. 

\bigskip
\noindent
\textbf{Prediction.} The prediction step simply means iterating the stochastic dynamics forward. Thus, obtaining $\hat{\pi}_{t+1}(x_{t+1})$ requires marginalizing 
over the current state $x_t$, weighted by the current filtering distribution $\pi_t(x_t)$. 
\begin{align}
\hat{\pi}_{t+1}(x_{t+1}) &= p(x_{t+1}|Y_t) \nonumber \\
				   &= \int p(x_t, x_{t+1}|Y_t) dx_t \nonumber \\ 
				   &= \int p(x_{t+1}|x_t, Y_t) p(x_t|Y_t) dx_t \nonumber \\
				   &= \int p(x_{t+1}|x_t) p(x_t|Y_t) dx_t \nonumber \\
				   &= \int \mathcal{N}_P(x_{t+1}|g(x_t), \Sigma_g) \pi_t(x_t) dx_t \label{prediction_operator}
\end{align}
Note that the fact that we need only integrate over the previous state $x_t$ depends completely on the Markov assumption in the dynamics model. Note also that this 
step is independent of $t$ due to the assumption that the dynamical model is time-homogenous. 

\bigskip
\noindent
\textbf{Analysis.} The analysis step entails combining the predictive distribution $\hat{\pi}_{t+1}(x_{t+1})$ with the observed data $y_{t+1}$. Hence, this step 
is simply an application of Bayes' rule. The analysis operator $\mathcal{A}_t$ is thus a likelihood operator, as the predictive distribution is simply weighted by 
the likelihood $p(y_{t+1}|x_{t+1})$. 
\begin{align}
\pi_{t+1}(x_{t+1}) &= p(x_{t+1}|Y_{t+1}) \nonumber \\
			   &= p(x_{t+1}|Y_t, y_{t+1}) \nonumber \\
			   &= \frac{p(y_{t+1}|x_{t+1}, Y_t)p(x_{t+1}|Y_t)}{p(y_{t+1}|Y_t)} \nonumber \\
			   &= \frac{p(y_{t+1}|x_{t+1})p(x_{t+1}|Y_t)}{p(y_{t+1}|Y_t)} \nonumber \\
			   &= \frac{\mathcal{N}_N(y_{t+1}|h(x_{t+1}), \Sigma_{\epsilon}) \hat{\pi}_{t+1}(x_{t+1})}{p(y_{t+1}|Y_t)} \label{analysis_operator}
\end{align}
Thus, $\mathcal{A}_t$ simply represents multiplication of $\hat{\pi}_{t+1}(x_{t+1})$ by the likelihood $\mathcal{N}_N(y_{t+1}|h(x_{t+1}), \Sigma_{\epsilon})$
and then normalization in order to result in a valid probability distribution. 

% The Linear Gaussian Model 
\section{Linear Gaussian Model}
The linear Gaussian model is the special case of the stochastic dynamics model \ref{stochastic_dynamics_model} where the one-step operator is linear 
\[g(x_t) = Gx_t, \text{ where } G \in \R^{P \times P}\]
as well as the observation operator 
\[h(x_t) = Hx_t, \text{ where } H \in \R^{N \times P}\]

\subsection{The Kalman Filter}
Under the linear Gaussian assumptions here, the prediction $\mathcal{P}$ and analysis $\mathcal{A}_t$ operators preserve Gaussianity. This implies that 
all of the predictive and filtering distributions are Gaussian. The Kalman filter is simply a recursive update that yields the updated mean and covariance matrix 
of the filtering distribution when new data arrives. In particular, note that this means that in the linear Gaussian setting the filtering distributions are available in 
closed-form. 

\begin{thm} \label{Kalman_Filter}
Under the linear Gaussian assumption, the filtering distributions $\{\pi_t\}_{t \in \mathbb{N}}$ and predictive distributions $\{\hat{\pi}_{t}\}_{t \in \mathbb{N}}$ are all 
Gaussian. 
\begin{align*}
\hat{\pi}_{t+1}(x_{t+1}) &= p(x_{t+1}|Y_{t}) = \mathcal{N}_P(x_{t+1}|\hat{\mu}_{t+1}, \hat{\Sigma}_{t+1}) \\
\pi_{t+1}(x_{t+1}) &= p(x_{t+1}|Y_{t+1}) = \mathcal{N}_P(x_{t+1}|\mu_{t+1}, \Sigma_{t+1})
\end{align*}
Moreover, the means and covariance matrices of these formulas satisfy the following recursions. 
\begin{align*}
\hat{\mu}_{t + 1} &= G \mu_{t} \\
\hat{\Sigma}_{t + 1} &= G \Sigma_t G^\top + \Sigma_g \\
\Sigma_{t + 1} &= \left[\hat{\Sigma}^{-1}_{t + 1} + H^\top \Sigma_{\epsilon}^{-1} H \right]^{-1} \\
\mu_{t + 1} &= \Sigma_{t + 1} \left[\hat{\Sigma}^{-1}_{t + 1}\hat{\mu}_{t + 1} + H^\top \Sigma_{\epsilon}^{-1} y_{t+1} \right] 
\end{align*}
\end{thm}

\begin{proof} 
We break the proof into the prediction and analysis steps. \\

\noindent
\textbf{Prediction}: For an inductive proof, suppose that $\pi_t = \mathcal{N}_P(\mu_t, \Sigma_t)$. We aim to show that 
$\hat{\pi}_{t + 1} = \mathcal{N}_P(\hat{\mu}_{t + 1}, \hat{\Sigma}_{t + 1})$ and find explicit formulas for the mean and covariance 
matrix in terms of $\mu_t$ and $\Sigma_t$. Recall from \ref{prediction_operator} that 
\[\hat{\pi}_{t + 1}(x_{t+1}) = \int \mathcal{N}_P(x_{t+1}|Gx_t, \Sigma_g) \pi_t(x_t) dx_t = \int \mathcal{N}_P(x_{t+1}|Gx_t, \Sigma_g) \mathcal{N}_P(x_{t}|\mu_t, \Sigma_t) dx_t \]
One way to approach this is to simply attempt to evaluate the integral. This would work, but is not the most efficient way. A simpler option 
is to consider that the above integral is actually the normalizing constant for the posterior $p(x_{t+1}|x_t)$ of the following linear Gaussian model 
\begin{align*}
x_{t + 1} &= Gx_t + \xi_t \\
x_t &\sim \mathcal{N}_P(\mu_t, \Sigma_t) \\
\xi_t &\sim \mathcal{N}_N(0, \Sigma_\epsilon)
\end{align*}
where $x_t$ is viewed as the ``parameter'' in the model and $x_{t+1}$ the ``data''. The normalizing constant (model evidence) here is 
$p(x_{t + 1}) = \hat{\pi}_{t + 1}(x_{t+1})$. But we see from the above model that $x_{t + 1}$ is simply a linear function of the Gaussian distributed 
random variables $x_t$, $\xi_t$ and hence $\hat{\pi}_{t + 1}(x_{t+1})$ is Gaussian $\mathcal{N}_P(\hat{\mu}_{t + 1}, \hat{\Sigma}_{t + 1})$. 
Moreover, the mean and covariance can be computed as 
\begin{align*}
\hat{\mu}_{t + 1} &= \E\left[Gx_t + \xi_t\right] = G\E[x_t] + 0 = G \mu_t \\
\hat{\Sigma}_{t + 1} &= \Cov(Gx_t + \xi_t) = G \Cov(x_t) G^{\top} + \Cov(\xi_t) = G \Sigma_t G^{\top} + \Sigma_{g}
\end{align*}
which uses the independence of $x_t$ and $\xi_t$. This verifies the characterization of the predictive distributions $\{\hat{\pi}_t\}_{t \in \mathbb{N}}$. 

\bigskip
\noindent
\textbf{Analysis}: Now, given that $\hat{\pi}_{t + 1} = \mathcal{N}_P(\hat{\mu}_{t + 1}, \hat{\Sigma}_{t + 1})$ we seek to show that 
$\pi_{t + 1} = \mathcal{N}_P(\mu_{t + 1}, \Sigma_{t + 1})$ and verify the recursive formulas for the mean and covariance. Recall from 
\ref{analysis_operator} that the filtering distribution $\pi_{t + 1}$ is obtained from the predictive distribution $\hat{\pi}_{t + 1}$ via 
multiplication by the likelihood. 
\begin{align*}
\pi_{t + 1}(x_{t + 1}) &\propto p(y_{t + 1}|x_{t + 1})\hat{\pi}_{t + 1}(x_{t+1}) \\
			       &= \mathcal{N}_N(y_{t + 1}|H x_{t+1}, \Sigma_\epsilon) \mathcal{N}_P(x_{t + 1}|\hat{\mu}_{t + 1}, \hat{\Sigma}_{t + 1})
\end{align*}
We can again view this as a linear Gaussian inverse problem. In particular $\pi_{t + 1}(x_{t + 1})$ is the posterior distribution $p(x_{t+1}|y_{t+1})$
of the following linear Gaussian model. 
\begin{align*}
y_{t + 1} &= Hx_{t + 1} + \epsilon \\
x_{t + 1} &\sim \mathcal{N}_{P}(\hat{\mu}_{t+1}, \hat{\Sigma}_{t+1}) \\
\epsilon &\sim \mathcal{N}_N(0, \Sigma_\epsilon)
\end{align*} 
Therefore, we immediately have that $\pi_{t + 1}(x_{t + 1})$ is Gaussian $\mathcal{N}_P(\mu_{t + 1}, \Sigma_{t + 1})$. The mean and covariance could 
be derived by simply applying the well-known formulas for the posterior distribution in the Gaussian linear model. However, for the sake of completeness 
I derive them from scratch here. By combining the exponentials in the two Gaussians being multiplied, we obtain 
\begin{align*}
\pi_{t + 1}(x_{t + 1}) \propto \exp\left(-\frac{1}{2} (y_{t+1} - Hx_{t+1})^{\top} \Sigma_\epsilon^{-1} (y_{t+1} - Hx_{t+1}) - \frac{1}{2} (x_{t+1} - \hat{\mu}_{t+1})^{\top} \hat{\Sigma}^{-1}_{t+1} (x_{t+1} - \hat{\mu}_{t+1}) ) \right)
\end{align*}
Since $\pi_{t + 1} = \mathcal{N}_P(\mu_{t + 1}, \Sigma_{t + 1})$ then it must be of the form 
\[\pi_{t + 1}(x_{t + 1}) \propto \exp\left(-\frac{1}{2} (x_{t + 1} - \mu_{t + 1})^{\top} \Sigma_{t+1}^{-1} (x_{t + 1} - \mu_{t + 1}) \right) \]
Thus, to obtain $\mu_{t + 1}$ and $\Sigma_{t + 1}$ we set the two above expressions for $\pi_{t + 1}(x_{t+1})$ equal and match up the terms, dropping 
terms without dependence on $x_{t+1}$ along the way. Expanding the two expressions yields
\begin{align*}
\pi_{t + 1}(x_{t + 1}) &\propto \exp\left(-\frac{1}{2} x_{t+1}^{\top}\left[H^\top \Sigma_{\epsilon}^{-1}H + \hat{\Sigma}_{t+1}^{-1} \right] x_{t+1} + x_{t+1}^{\top} \left[H^\top \Sigma_{\epsilon}^{-1}y_{t+1} + \hat{\Sigma}_{t+1}^{-1}\hat{\mu}_{t+1} \right] \right)
\end{align*}
and 
\begin{align*}
\pi_{t + 1}(x_{t + 1}) &\propto \exp\left(-\frac{1}{2} x_{t + 1}^\top \Sigma_{t+1}^{-1} x_{t+1} + x_{t+1}^\top \Sigma_{t+1}^{-1} \mu_{t+1} \right)
\end{align*}
respectively. Equating the coefficients on the quadratic and linear terms gives
\begin{align*}
\Sigma_{t + 1}^{-1} &= \hat{\Sigma}_{t+1}^{-1} + H^{\top} \Sigma_{\epsilon}^{-1} H \\
\Sigma_{t+1}^{-1} \mu_{t+1} &= H^\top \Sigma_{\epsilon}^{-1}y_{t+1} + \hat{\Sigma}_{t+1}^{-1}\hat{\mu}_{t+1}
\end{align*}
which then implies
\begin{align*}
\Sigma_{t+1} &= \left[\hat{\Sigma}_{t+1}^{-1} + H^{\top} \Sigma_{\epsilon}^{-1} H \right]^{-1} \\
\mu_{t + 1} &= \Sigma_{t+1} \left[\hat{\Sigma}_{t+1}^{-1}\hat{\mu}_{t+1} + H^{\top} \Sigma_{\epsilon}^{-1}y_{t+1} \right]
\end{align*}
\end{proof}
I consider some initial observations about the Kalman update formulas. The covariance update only depends on the forward model, 
observation operator, and observation covariance, and \textit{not} on the observed data. This is analogous to the result that the 
posterior covariance of the linear Gaussian model does not depend on the observed data. We also notice that the update formulae 
for the mean are affine in both the prediction and analysis steps. The update formula for the covariance is affine in the prediction 
step, but non-linear in the analysis step due to the inverse. The update formula for the precision matrix $\Sigma_{t+1}^{-1}$, however, 
is affine. Also note that the update for $\Sigma_{t+1}$ requires the computation of the inverse of a $P \times P$ matrix. If the number of 
states $P$ is very large, this can prove computationally intractable due to the $O(P^3)$ scaling. A more computationally efficient implementation 
is discussed later in this section, and then next section discusses the ensemble Kalman filter, which can provide a more scalable sample-based 
approximation to the Kalman update. 

The next result establishes that the positive definiteness of the covariance of the filtering distribution is preserved by the Kalman updates. 

\begin{lemma} 
The covariances $\hat{\Sigma}_t$ and $\Sigma_t$ are positive definite for all $t = 0, 1, 2, \dots$. 
\end{lemma}

\begin{proof}
By assumption, $\Sigma_0$ is positive definite. Proceeding inductively, suppose that $\Sigma_t$ is positive definite. We aim to show that $\hat{\Sigma}_{t+1}$
and $\Sigma_{t + 1}$ are also positive definite. I will use the fact that the inverse of a positive definite matrix is positive definite. Let $0 \neq x \in \R^P$ 
Beginning with $\hat{\Sigma}_{t+1}$, we have 
\begin{align*}
x^{\top} \hat{\Sigma}_{t+1} x &= x^{\top} \left[G \Sigma_t G^{\top} + \Sigma_g \right] x \\
				      &= x^{\top} G \Sigma_t G^{\top} x + x^{\top} \Sigma_g x \\
				      &= \norm{\Sigma_t^{1/2}G^\top x}_2^2 + x^\top \Sigma_g x \\
				      &\geq x^\top \Sigma_g x \\
				      &> 0
\end{align*}
where the last line uses the assumption that $\Sigma_g$ is positive definite. Continuing with $\Sigma_{t+1}$, I will show that $\Sigma^{-1}_{t+1}$
is positive definite definite, which is sufficient to show that $\Sigma_{t+1}$ is positive definite as well. 
\begin{align*}
x^{\top} \Sigma_{t + 1}^{-1} x &= x^{\top} \left[\hat{\Sigma}^{-1}_{t+1} + H^{\top} \Sigma_\epsilon^{-1}H \right] x \\
				       &= x^{\top} \hat{\Sigma}^{-1}_{t+1} x + x^{\top} H^{\top} \Sigma_\epsilon^{-1}H x \\
				       &= x^{\top} \hat{\Sigma}^{-1}_{t+1} x + \norm{\Sigma_\epsilon^{-1/2} H x}_2^2 \\
				       &\geq x^{\top} \hat{\Sigma}^{-1}_{t+1} x \\
				       &> 0
\end{align*}
where the last step uses the above result that $\hat{\Sigma}^{-1}_{t+1}$ is positive definite. This concludes the proof. 
\end{proof}

% Computational Considerations 
\subsubsection{Computational Considerations}
It turns out that the $O(P^3)$ matrix inversion discussed above can be avoided, and replaced by an $O(N^3)$ inversion. This can be quite advantageous 
when the dimension of the state space is much larger than the dimension of the observed data. The alternate form of the update can be derived via an 
application of the Woodbury matrix identity. 

\begin{prop} (Stuart et al, Lemma 8.6) \label{Woodbury}
Let $A \in \R^{p \times p}$, $U \in \R^{p \times q}$, $B \in \R^{q \times q}$, $V \in \R^{q \times p}$. If $A$ and $B$ are positive definite then $A + UBV$ is invertible 
and 
\[(A + UBV)^{-1} = A^{-1} - A^{-1} U\left(B^{-1} + VA^{-1}U\right)VA^{-1}\]
\end{prop}

We now apply the Woodbury identity to the covariance update in the analysis step of the Kalman filter, which converts the $O(P^3)$ matrix inverse to a $O(N^3)$ 
matrix inverse. 

\begin{lemma} 
The expression 
\[\Sigma_{t + 1} = \left[\hat{\Sigma}^{-1}_{t + 1} + H^\top \Sigma_{\epsilon}^{-1} H \right]^{-1}\]
from \ref{Kalman_Filter} can be re-written as 
\[\Sigma_{t + 1} = \left(I_P - K_{t+1}H \right)\hat{\Sigma}_{t+1}\]
where 
\[K_{t+1} := \hat{\Sigma}_{t+1} H^{\top} \left[H\hat{\Sigma}_{t+1} H^\top + \Sigma_{\epsilon} \right]^{-1} \]
\end{lemma}

\begin{proof}
Applying the Woodbury identity \ref{Woodbury}, 
\begin{align*}
\Sigma_{t + 1} &= \left[\hat{\Sigma}^{-1}_{t + 1} + H^\top \Sigma_{\epsilon}^{-1} H \right]^{-1} \\
		       &= \hat{\Sigma}_{t + 1} - \hat{\Sigma}_{t + 1} H^{\top} \left(\Sigma_{\epsilon} + H\hat{\Sigma}_{t + 1}H^\top \right)^{-1} H \hat{\Sigma}_{t + 1} \\
		       &= \hat{\Sigma}_{t + 1} - K_{t+1} H \hat{\Sigma}_{t + 1} \\
		       &= \left(I_P - K_{t+1}H \right)\hat{\Sigma}_{t+1}
\end{align*}
\end{proof}
The matrix $K_{t + 1}$ is known as the \textbf{Kalman gain}, because it quantifies how much uncertainty is reduced after observing $y_{t+1}$. The matrix 
 $I_P - K_{t+1}H$ can be viewed as an operator that transforms $\hat{\Sigma}_{t+1}$ into $\Sigma_{t + 1}$ by accounting for the new information obtained 
 from the observation $y_{t+1}$. 
 
\textbf{TODO: Write Kalman mean update in terms of Kalman gain.} 

% Optimization Perspective 
\subsubsection{Optimization Perspective}
Recall that the analysis map $\mathcal{A}_{t}$ simply weights the predictive distribution $\hat{\pi}_{t+1}(x_{t+1})$ by the likelihood $p(y_{t+1}|x_{t+1})$ and then 
normalizes in order to produce a valid probability distribution. 
\begin{align*}
\pi_{t + 1}(x_{t + 1}) &\propto \exp\left(-\frac{1}{2} (y_{t+1} - Hx_{t+1})^{\top} \Sigma_\epsilon^{-1} (y_{t+1} - Hx_{t+1}) - \frac{1}{2} (x_{t+1} - \hat{\mu}_{t+1})^{\top} \hat{\Sigma}^{-1}_{t+1} (x_{t+1} - \hat{\mu}_{t+1}) ) \right) \\
			       &= \exp\left(-\frac{1}{2} \norm{y_{t+1} - Hx_{t+1}}^2_{\Sigma_\epsilon} - \frac{1}{2} \norm{x_{t+1} - \hat{\mu}_{t+1}}^2_{\hat{\Sigma}^{-1}_{t+1}} \right) 
\end{align*}
Knowing that $\pi_{t + 1}(x_{t + 1})$ is Gaussian, and that the mean of the Gaussian distribution corresponds to its mode we have that 
\begin{align*}
\mu_{t + 1} &= \text{argmax}_{x_{t+1}} \pi_{t+1}(x_{t+1}) \\
		  &= \text{argmin}_{x_{t+1}} \left( \frac{1}{2} \norm{y_{t+1} - Hx_{t+1}}^2_{\Sigma_\epsilon} - \frac{1}{2} \norm{x_{t+1} + \hat{\mu}_{t+1}}^2_{\hat{\Sigma}^{-1}_{t+1}} \right)
\end{align*}
In other words, the Kalman filter sets the $\mu_{t+1}$ to the solution of the above dual objective least-squares optimization problem. The competing objectives are a measure of fit 
to the observed observation $y_{t+1}$ and a measure of agreement with the predictive mean $\hat{\mu}_{t+1}$. The matrices $\Sigma_\epsilon$ and $\hat{\Sigma}^{-1}_{t+1}$
control the relative weight given to each quadratic objective. 


% Extended and Ensemble Kalman Filter
\section{The Extended and Ensemble Kalman Filter}
I consider two extensions of the Kalman filter here that approximate the filtering distributions in a more general setting. In particular, we depart from the linear 
Gaussian model by allowing the forward model to be non-linear, while maintaining the assumption that the observation operator is linear. 
\begin{align}
&x_{t + 1} = g(x_t) + \xi_t, && \xi_t \overset{iid}{\sim} \mathcal{N}(0, \Sigma_x) \\
&y_{t + 1} = Hx_{t+1} + \epsilon_{t+1}, && \epsilon_t \overset{iid}{\sim} \mathcal{N}(0, \Sigma_\epsilon) \nonumber 
\end{align}
Allowing $g(\cdot)$ to be nonlinear has the consequence that the prediction operator $\mathcal{P}$ will no longer preserve Gaussianity. Therefore, the predictive 
distribution $\hat{\pi}_{t+1}$ will no longer be available in closed-form. The extended Kalman filter (ExKF) addresses this by employing a linear approximation, while 
the ensemble Kalman filter (EnKF) utilizes a sample-based approximation. 

% Extended Kalman Filter
\subsection{Extended Kalman Filter}
The main idea of the ExKF is to employ a linear approximation to propagate $\Sigma_t$ to $\hat{\Sigma}_{t + 1}$. I derive this method by attempting to perform the same 
calculations used by the Kalman filter to obtain $\hat{\mu}_{t + 1}$ and $\hat{\Sigma}_{t + 1}$ and observing where we run into issues due to the non-linear $g(\cdot)$. 
Recall that the predictive distribution is defined as $\hat{\pi}_{t + 1}(x_{t+1}) = p(x_{t+1}|Y_t)$. In the Kalman filter derivations, we could simply obtain closed-form 
solutions for $\hat{\mu}_{t + 1} = \E[x_{t + 1}|Y_t]$ and $\hat{\Sigma}_{t+1} = \Cov(x_{t+1}|Y_t)$. I now consider computing this moments in this more general setting. 
\begin{align*}
\E[x_{t + 1}|Y_t] &= \E\left[g(x_t) + \xi_t|Y_t\right] = \E\left[g(x_t)|Y_t\right] + \E[\xi_t|Y_t] = \E\left[g(x_t)|Y_t\right] \\
\Cov(x_{t+1}|Y_t) &= \Cov\left(g(x_t) + \xi_t|Y_t]\right) = \Cov\left(g(x_t)|Y_t\right) + \Cov(\xi_t|Y_t) = \Cov\left(g(x_t)|Y_t\right) + \Sigma_g
\end{align*}
These derivations rely on the independence assumptions $\{\xi_t\} \perp \{\epsilon_t\} \perp x_0$. The mean and covariance cannot be reduced further, as in the linear 
case. Thus, we turn to approximations. For the mean, we suppose that the distribution $\pi_t$ is concentrated about its mean $\mu_t$ so that $g(x_t) \approx g(\mu_t)$. 
Applying this approximation, we then obtain  
\begin{align*}
\E\left[g(x_t)|Y_t\right] \approx \E\left[g(\mu_t) |Y_t \right] = g(\mu_t)
\end{align*}
In other words, we set the predictive mean to the value obtained by simply propagating the previous mean $\mu_t$ forward one time step. For the covariance approximation, 
we consider the linearization (i.e. first order Taylor series approximation) of the forward model $g(\cdot)$ centered at the point $\mu_t$: 
\[g(x_t) - g(\mu_t) \approx Dg(\mu_t)\left(x_t - \mu_t \right) \]
 Plugging this in, we have 
 \begin{align*}
 \Cov\left(g(x_t)|Y_t\right) &= \E\left[\left(g(x_t) - \E[g(x_t)|Y_t]\right)\left(g(x_t) - \E[g(x_t)|Y_t]\right)^{\top} | Y_t \right] \\
 				       &\approx \E\left[\left(g(x_t) - g(\mu_t)\right)\left(g(x_t) - g(\mu_t)\right)^{\top} | Y_t \right] \\
				       &\approx \E\left[Dg(\mu_t)\left(x_t - \mu_t \right) \left(x_t - \mu_t \right)^{\top} Dg(\mu_t)^\top  | Y_t \right] \\
				       &= Dg(\mu_t) \E\left[\left(x_t - \mu_t \right) \left(x_t - \mu_t \right)^{\top} | Y_t \right] Dg(\mu_t)^\top \\
				       &= Dg(\mu_t) \Cov(x_t|Y_t) Dg(\mu_t)^\top \\
				       &= Dg(\mu_t) \Sigma_t Dg(\mu_t)^\top
 \end{align*}
 The second line applies the same approximation $g(x_t) \approx g(\mu_t)$ as in the approximation used for the mean above. The third line inserts the linear approximation.
 Summarizing, we employ the following approximations for $\hat{\mu}_{t + 1}$ and $\hat{\Sigma}_{t + 1}$ to approximate the prediction step in the filtering problem. 
 \begin{align}
 \hat{\mu}_{t + 1} &= g(\mu_t) \label{ExKF_approximations} \\
 \hat{\Sigma}_{t + 1} &= Dg(\mu_t) \Sigma_t Dg(\mu_t)^\top + \Sigma_g \nonumber
 \end{align} 
The analysis step is then unchanged from the standard Kalman filter. Note that the quality of approximation in the prediction step depends heavily on the assumption that 
the distribution $\pi_t$ is concentrated about its mean. This means that we require $\Sigma_g$ and $\Sigma_{\epsilon}$ to be small in order for the approximation to 
be reasonable. 

% Ensemble Kalman Filter
\subsection{Ensemble Kalman Filter}
Notice that the Jacobian $Dg(\mu_t)$ is a $P \times P$ matrix. If the number of states $P$ is very large then computation and storage of this matrix becomes 
intractable. The Ensemble Kalman Filter (EnKF) was introduced to overcome this issue, replacing the local linearization with a sample-based approximation. 
The main idea is to propagate an ensemble of ``particles'' (i.e. samples) and approximate $\hat{\Sigma}_{t + 1}$ by using the empirical covariance matrix estimator 
computed on the particles. We continue assuming that the forward operator $g: \R^P \to \R^P$ is non-linear but the observation operator $H: \R^P \to \R^N$ is 
linear. However, note that there are many variations of the EnKF that apply under differing assumptions. 

We let $\{x_t^{(k)}\}_{k = 1}^{K}$ denote the ensemble of particles at time $t$. All particles are weighted equally, as opposed to other ensemble-based filtering 
algorithms discussed later. We might imagine constructing a sample-based approximation to the filtering distribution; something like, 
\begin{align*}
\pi_t^{N}(x) &:= \frac{1}{K} \sum_{k = 1}^{K} \delta(x_t^{(k)} - x)
\end{align*}
or something more sophisticated like a kernel density estimate. However, when $N$ is modest in size and/or the true distribution $\pi_t$ is far from Gaussian, 
such density estimates can be quite poor. Instead, the EnKF can be thought of as a sort of sequential optimization method, which will be described in more depth 
later. For now, we provide details on the how the prediction and analysis steps are performed using the ensemble of particles. 

\bigskip
\noindent
\textbf{Prediction.} Recall from the Kalman filter that the prediction step proceeds by accounting for the uncertainty in stepping the model one time step into 
the future, thus obtaining the distribution $\hat{\pi}_{t+1}(x_{t+1}) = p(x_{t+1}|Y_t)$. The ensemble-based equivalent of this is to feed each particle through one 
step of the dynamical model. Thus the ensemble is updated 
\[\{x_t^{(k)}\} \to \{\hat{x}_{t+1}^{(k)}\}\]
via 
\begin{align*}
\hat{x}_{t+1}^{(k)} &= g(x_t^{(k)}) + \xi_t,  &&k = 1, \dots, K
\end{align*}
Note that this involves mapping each particle by $g(x_t^{(k)})$ and then perturbing the result by adding noise $\xi_t \sim \mathcal{N}_P(0, \Sigma_g)$. Now 
the predictive mean $\hat{\mu}_{t+1}$ and covariance $\hat{\Sigma}_{t+1}$ can be estimated via the sample analogs. 
\begin{align*}
\hat{\mu}_{t+1} &= \frac{1}{K} \sum_{k = 1}^{K} \hat{x}_{t+1}^{(k)} \\
\hat{\Sigma}_{t+1} &= \frac{1}{K} \sum_{k = 1}^{K} \left(\hat{x}_{t+1}^{(k)} - \hat{\mu}_{t+1} \right) \left(\hat{x}_{t+1}^{(k)} - \hat{\mu}_{t+1} \right)^\top
\end{align*}

\bigskip
\noindent
\textbf{Analysis.} Recall that the analysis step of the Kalman filter can be written 
\begin{align*}
\mu_{t+1} &= (I - K_{t+1}H) \hat{\mu}_{t+1} + K_{t+1} y_{t+1} \\
\Sigma_{t+1} &= (I - K_{t+1}H) \hat{\Sigma}_{t+1}
\end{align*}
where 
\[K_{t+1} = \hat{\Sigma}_{t+1} H^\top \left[H \hat{\Sigma}_{t+1}H^\top + \Sigma_{\epsilon}^{-1}   \right]^{-1} \]
is the \textit{Kalman gain}. The mean is seen to be a compromise between the predictive mean $\hat{\mu}_{t+1}$ and data 
$y_{t+1}$ with the relative weights controlled by the Kalman gain. The Kalman gain also controls the update 
$\hat{\Sigma}_{t+1} \to \Sigma_{t+1}$.  

The EnKF defines the Kalman gain identically, with the empirical covariance matrix $\hat{\Sigma}_{t+1}$ replacing the exact covariance used in the Kalman 
filter. Thus, $\Sigma_{t+1}$ is updated using the same Kalman filter equations. The particles are updated via the equation for the Kalman mean update. 
\begin{align}
&x^{(k)}_{t+1} = (I - K_{t+1}H) \hat{x}^{(k)}_{t+1} + K_{t+1} y_{t+1} && k = 1, 2, \dots, K \label{EnKF_analysis_update}
\end{align}
We recall that the Kalman mean update can be viewed as solving a dual objective least squares optimization problem. Therefore, the above particle update 
can also be understood as solving the following problem. 
\begin{align*}
x^{(k)}_{t+1} &= \text{argmin}_{x} J_k(x) \\
J_k(x) &= \norm{y_{t+1} - H x}^2_{\Sigma_{\epsilon}} + \norm{x - \hat{x}^{(k)}_{t+1}}^2_{\Sigma_g}
\end{align*}

\subsubsection{Perturbed Observation EnKF}
A natural question is whether the EnKF is truly an exact sample-based approximation to the Kalman filter in the linear Gaussian setting. By this I mean the following: 
supposing the forward model $g$ is linear, do we have 
\[x^{(k)}_{t+1} \overset{iid}{\sim} \pi_{t+1} \]
i.e., are the particles independent samples of the true filtering distribution? The answer is currently \textit{no}. To intuitively see why,  
look back at the analysis update \ref{EnKF_analysis_update} to the particles. The update equation is using the fixed observation $y_{t+1}$. However, as we know, 
the Kalman filter update propagates forward the uncertainty in the measurement process, accounting for the noise $\epsilon_t$. In order to capture this uncertainty 
in the sample-based approximation, we must perturb the observation $y_{t+1}$ in a similar manner that the particles are perturbed by $\xi_t$ in the prediction step. 
\begin{align}
&x^{(k)}_{t+1} = (I - K_{t+1}H) \hat{x}^{(k)}_{t+1} + K_{t+1} y^{(k)}_{t+1} \label{EnKF_analysis_update_perturbed_obs} \\
&y^{(k)}_{t+1} \overset{iid}{\sim} \mathcal{N}_N(y_{t+1}, \Sigma_{\epsilon}), && k = 1, 2, \dots, K \nonumber 
\end{align}
We now prove that this perturbed-observation EnKF is indeed an exact sample-based approximation of the Kalman updates in the linear Gaussian setting. However, we 
must be very clear about what the below proof actually shows. It establishes that both the \textit{prediction} and \textit{analysis} EnKF updates provide sample-based 
approximations of the Kalman updates in the linear Gaussian setting. It does \textit{not} show that the full two-step update 
\[\{x^{(k)}_t\} \to \{\hat{x}^{(k)}_{t+1}\} \to \{x^{(k)}_{t+1}\}\]
The reason this does not not immediately follow is due to the fact that the covariance $\hat{\Sigma}_{t+1}$ is also estimated from the ensemble. The fact that the 
analysis update is non-linear in $\hat{\Sigma}_{t+1}$ complicates matters. The below result instead shows that, \textit{conditional on } $\hat{\Sigma}_{t+1}$ the 
distribution is preserved, which is much easier to establish. It is indeed true that the EnKF converges to the Kalman filter as $K \to \infty$, but such a proof is outside 
of the scope of these notes. 

\begin{thm} 
Assume the forward model is linear, given by $g(x) = Gx$. 
\begin{enumerate}
\item \textbf{Prediction:} Suppose that $x^{(k)}_{t} \sim \mathcal{N}_D(\mu_t, \Sigma_t)$. Then the EnKF prediction update yields 
\[\hat{x}^{(k)}_{t + 1} \sim \mathcal{N}_D(G\mu_t, G\Sigma_t G^T + \Sigma_g)\] 
\item \textbf{Analysis:} Suppose that $\hat{x}^{(k)}_{t + 1} \sim \mathcal{N}_D(\hat{\mu}_{t+1}, \hat{\Sigma}_{t+1})$. Then the EnKF analysis update yields 
\[x^{(k)}_{t+1} \sim \mathcal{N}_D(\hat{\mu}_{t+1} + K_{t+1}(y_{t+1} - H\hat{\mu}_{t+1}), \left(I_P - K_{t+1}H \right)\hat{\Sigma}_{t+1})\]
\end{enumerate}
where 
\[K_{t+1} := \hat{\Sigma}_{t+1} H^{\top} \left[H\hat{\Sigma}_{t+1} H^\top + \Sigma_{\epsilon} \right]^{-1} \]
Notice that the moments of the two Gaussian distributions align with the Kalman filter formulae. 
\end{thm}

\begin{proof} 
The first part of this proof concerns showing that the predictive ensemble $\{\hat{x}^{(k)}_{t+1}\}$ is distributed according to the true predictive distribution.
 The second part shows that the perturbed-observation EnKF analysis update results in an ensemble with distribution that agrees with the distribution 
 resulting from the true Kalman filter update.  
 
\bigskip
\noindent
\textbf{Prediction.} There is almost nothing to prove here, as the predictive ensemble is formed by propagating the samples through the model 
\begin{align*}
&\hat{x}^{(k)}_{t+1} = Gx_t^{(t)} + \xi^{(k)}_t, && \xi^{(k)}_t \overset{iid}{\sim} \mathcal{N}_D(0, \Sigma_g) 
\end{align*}
Since $x_t^{(t)} \sim \mathcal{N}_D(\mu_t, \Sigma_t)$ then the above linear update preserves Gaussianity. The resulting distribution is given by 
\[\hat{x}^{(k)}_{t+1} \sim \mathcal{N}_D(G\mu_t, G\Sigma_t G + \Sigma_g) = \mathcal{N}_D(\hat{\mu}_{t+1}, \hat{\Sigma}_{t+1})\]



\bigskip
\noindent
\textbf{Analysis.}

\end{proof}

\end{document} 



