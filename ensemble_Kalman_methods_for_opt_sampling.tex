\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Local custom commands. 
\include{local-defs-EKI}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{alg}{Algorithm}
\newtheorem{dynamics}{Artificial Dynamics}

% Title and author
\title{Ensemble Kalman Methods for Inversion: Optimization and Sampling}
\author{Andrew Roberts}

\begin{document}

\maketitle
\newpage

% Background
\section{Background}

\subsection{Inverse Problems}

\subsection{Filtering Stochastic Dynamical Systems}
We begin by considering a dynamical system which is subject to noise, coupled with an associated observation process. 
We utilize the notation 
\begin{align}
\dstate[\timeStep+1] &= \fwdOne(\dstate) + \indexTimeStep{\noiseDynamic}, 	  		 		 &&\indexTimeStep{\noiseDynamic} \overset{iid}{\sim} \Gaussian(0, \CovNoiseDynamic) \label{dynamic_model} \\
\ddataObs[\timeStep+1] &= \obsOp(\dstate[\timeStep+1]) + \indexTimeStep[\timeStep+1]{\noiseObs}, &&\indexTimeStep[\timeStep+1]{\noiseObs} \overset{iid}{\sim} \Gaussian(0, \CovNoiseObs) \nonumber \\
\dstate[0] &\sim \Gaussian(\stateMean[0], \stateCov[0]) && \nonumber \dstate[0] \perp \{\indexTimeStep{\noiseDynamic}\} \perp \{\indexTimeStep{\noiseObs}\}, \nonumber 
\end{align}
where $\dstate \in \R^{\dimState}$ is the latent state of interest, described by a deterministic evolution operator $\fwdOne: \R^{\dimState} \to \R^{\dimState}$ which is perturbed by 
Gaussian noise $\indexTimeStep{\noiseDynamic}$. The third line gives a probabilistic initial condition for the dynamical system, also assumed to be Gaussian. 
The second line describes the observation process, in which the observed data $\ddataObs \in \R^{\dimObs}$ is modeled as a
function $\obsOp$ of the underlying state, perturbed by Gaussian observation noise $\noiseObs$. The final line also gives the crucial assumption that the dynamics noise, observation 
noise, and initial condition are all independent. Letting $\dataObsCum := \{\ddataObs[1], \dots, \ddataObs\}$ denote the accumulation of data up through time $\timeStep$, the primary 
target of inference is the \textit{filtering distribution} $\filterMeas$ of the state $\dstate$ given $\dataObsCum$, 
\begin{align}
\dstate|\dataObsCum \sim \filterMeas.
\end{align}
We typically assume the probability measure $\filterMeas$ has a density $\filterDens$ with respect to Lebesgue measure, such that 
\[
\filterMeas(A) = \int_A \filterDens(\state) d\state. 
\]
We now consider how the measure $\filterMeas$ is transformed into $\filterMeas[\timeStep+1]$ one time step in the future. In light of the dynamical model \ref{dynamic_model}, this transformation 
proceeds in two stages. 
\begin{enumerate}
\item \textbf{Prediction:} First the state distribution is propagated through the forward dynamics model. Noting that this model is Markovian, this can be formulated in terms of the associated 
Markov transition kernel $\predictOp$, which we note is time-homogenous under the model assumptions. We denote the distribution resulting from this operation as $\predictMeas[\timeStep+1]$
(with associated density $\predictDens[\timeStep+1]$, when applicable) and refer to it as the \textit{predicted distribution}. This distribution is given by 
\begin{align}
\predictMeas[\timeStep+1](A) := \filterMeas \predictOp(A) &= \int \predictOp(\state, A) \filterMeas(d\state).
\end{align}
We note that the operator $\predictOp$ is linear in the space of measures, and preserves probability measures under convex combinations. Under the model assumptions, this operator 
takes the concrete form 
\begin{align*}
\predictOp(\state, A) &= \int_A \Gaussian(\state^\prime | \state, \CovNoiseDynamic) d\state^\prime
\end{align*}
so that 
\begin{align}
\predictMeas[\timeStep+1](A) &= \int \left[\int_A \Gaussian(\state^\prime | \state, \CovNoiseDynamic) d\state^\prime\right] \filterMeas(d\state). \label{predict_integral}
\end{align}

\item \textbf{Analysis}: In the next stage the predicted distribution $\predictMeas[\timeStep+1]$ is combined with the new observation $\ddataObs[\timeStep+1]$ via Bayes' rule.
This operation can be formalized by the application of an operator $\analysisOp$, which depends on time through the observation $\ddataObs[\timeStep+1]$. Under the independence 
assumptions in \ref{dynamic_model}, this application of Bayes' rule can be written as 
\begin{align*}
\filterMeas[\timeStep+1](A) = \predictMeas[\timeStep+1] \analysisOp(A) = \frac{\int_A \Gaussian(\ddataObs[\timeStep+1]|\obsOp(\state), \CovNoiseObs) \predictMeas[\timeStep+1](d\state)}{\int \Gaussian(\ddataObs[\timeStep+1]|\obsOp(\state), \CovNoiseObs) \predictMeas[\timeStep+1](d\state)}.
\end{align*}
We notice that the numerator defines a linear operator in $\filterMeas[\timeStep+1]$. However, this linear operator is then composed with a non-linear operator which normalizes the measure 
in order to return a probability measure. The operator $\analysisOp$ is thus non-linear. 
\end{enumerate}

We have shown that the filtering distribution update is given by 
\begin{align}
\filterMeas[\timeStep+1] = \predictMeas[\timeStep+1] \analysisOp = \filterMeas \predictOp \analysisOp,
\end{align}
with $\predictOp$ linear Markov operator, and $\analysisOp$ a non-linear likelihood operator. The standard goal in the filtering setting is to approximate these operations in order 
to obtain an approximation of $\filterMeas[\timeStep+1]$. 

\subsection{The Kalman and Ensemble Kalman Filter}

\subsubsection{The Kalman Filter}
Under the additional assumption that the operators $\fwdOne$ and $\obsOp$ in \ref{dynamic_model} are linear, then the filtering distribution update can be performed 
analytically. We show in turn that the operators $\predictOp$ and $\analysisOp$ preserve Gaussianity. Suppose that the current filtering distribution is given by 
$\dstate|\dataObsCum \sim \Gaussian(\stateMean, \stateCov)$. 

\begin{enumerate}
\item \textbf{Prediction}: The prediction update simply follows from noting that 
\begin{align*}
\dstate[\timeStep+1] &= \fwdOne \dstate + \indexTimeStep{\noiseDynamic}, 
&&\dstate \sim \Gaussian(\stateMean, \stateCov), \indexTimeStep{\noiseDynamic} \sim \Gaussian(0, \CovNoiseDynamic)
\end{align*}
under the assumption that $\fwdOne$ is linear implies that $\dstate[\timeStep+1]$ is also Gaussian. Thus, 
\begin{align*}
\dstatePred[\timeStep+1] &\sim \Gaussian(\stateMeanPred[\timeStep+1], \stateCovPred[\timeStep+1]) \\
\stateMeanPred[\timeStep+1] &:= \fwdOne \stateMean \\
\stateCovPred[\timeStep+1]  &:= \fwdOne \stateCov \fwdOne^\top + \CovNoiseDynamic.
\end{align*}

\item \textbf{Analysis}: We write the observation operator as $\obsOpLin \in \R^{\dimObs \times \dimState}$ when it is assumed linear. 
The updated filtering density is given by 
\begin{align*}
\filterDens[\timeStep+1](\dstate[\timeStep+1]) 
&= p(\dstate[\timeStep+1] | \dataObsCum, \ddataObs[\timeStep+1]) \\
&\propto p(\ddataObs[\timeStep+1] | \dstate[\timeStep+1]) \filterDensPred(\dstate[\timeStep+1]) \\
&= \Gaussian(\ddataObs[\timeStep+1] | \obsOpLin \dstate[\timeStep+1], \CovNoiseObs) \Gaussian(\dstate[\timeStep+1] | \stateMeanPred[\timeStep+1], \stateCovPred[\timeStep+1]).
\end{align*}
The analysis update thus reduces to finding the posterior distribution of a standard Gaussian linear regression model. The well-known form of the posterior gives 
\begin{align*}
\dstate[\timeStep+1] | \dataObsCum[\timeStep+1] &\sim \Gaussian(\stateMean[\timeStep+1], \stateCov[\timeStep+1]) \\
\stateCov[\timeStep+1] &= \left[\stateCovPred[\timeStep+1]^{-1} + \obsOpLin^\top \CovNoiseObs^{-1} \obsOpLin \right]^{-1} \\
\stateMean[\timeStep+1] &= \stateCov[\timeStep+1] \left[\stateCovPred[\timeStep+1]^{-1} \stateMeanPred[\timeStep+1] + \obsOpLin^\top \CovNoiseObs^{-1} \ddataObs[\timeStep+1] \right].
\end{align*}  
In applications with high-dimensional state spaces such that $\dimState >> \dimObs$, the inversion of the $\dimState \times \dimState$ matrix in the above update formula may be 
computationally intractable. An application of the Woodbury matrix identity allows these formulae to be re-written in terms of an $\dimObs \times \dimObs$ matrix inverse. 
The equivalent mean and covariance update is given by
\begin{align*}
\stateCov[\timeStep+1] &= \left[\idMat_{\dimState} - \KGain[\timeStep+1] \obsOpLin \right] \stateCovPred[\timeStep+1] \\
\stateMean[\timeStep+1] &= \stateMeanPred[\timeStep+1] + \KGain[\timeStep+1] \left[\ddataObs[\timeStep+1] - \obsOpLin \stateMeanPred[\timeStep+1] \right] \\
\KGain[\timeStep+1] &:= \stateCovPred[\timeStep+1] \obsOpLin^\top \left[\obsOpLin \stateCovPred[\timeStep+1] \obsOpLin^\top + \CovNoiseObs \right]^{-1}
\end{align*}
where the matrix $\KGain[\timeStep+1]$ is referred to as the \textit{Kalman gain}. 
\end{enumerate}


\subsubsection{The Ensemble Kalman Filter}


\subsection{Langevin Diffusions}

% An Introduction Ensemble Kalman Methods for Inverse Problems.
\section{An Introduction Ensemble Kalman Methods for Inverse Problems}
We now turn our attention to the application of ensemble Kalman methods to the solution of Bayesian inverse problems. 
The generic setting of interest is 
\begin{align}
\dataObs &= \fwd(\spar) + \noise \label{inverse_problem} \\
\noise &\sim \Gaussian(0, \covObsNoise) \nonumber \\
\spar &\sim \Gaussian(\priorMean, \priorCov), \nonumber
\end{align}
where $\spar \in \R^{\Npar}$ is the unknown parameter of interest and $\dataObs \in \R^{\dimData}$ is an observed 
data vector which is assumed to result from a potentially non-linear forward mapping $\fwd: \R^{\Npar} \to \R^{\dimData}$
corrupted by Gaussian noise $\noise$. We consider the Bayesian approach, whereby the parameter is equipped with 
Gaussian prior and the goal is to characterize the posterior distribution $\spar|\dataObs \sim \postMeas$. 

We start by discussing an early instantiation of this idea, giving rise to the most basic ensemble Kalman inversion (EKI) algorithm. 
While there are many ways to introduce the EKI algorithm, we start with the motivation used in the paper, which first introduced 
the EKI algorithm. This method introduces an artificial dynamical system via an extended state space approach, whereby the 
inverse problem is embedded as the observation equation of the system. We begin 
by noting that \ref{inverse_problem} can be viewed as a rather trivial dynamical system with state vector $\spar$,
\begin{align}
\dpar[\timeStep+1] &\sim \Gaussian(\priorMean, \priorCov) \label{inverse_problem_dynamic1} \\
\indexTimeStep[\timeStep+1]{\dataObs} &= \fwd(\dpar[\timeStep+1]) + \indexTimeStep[\timeStep+1]{\noise}. \nonumber
\end{align}
In this formulation, $\fwd$ is thought of as the observation operator. In order to re-write \ref{inverse_problem_dynamic1}
in a form more suitable to application of the EnKF, we would like the observation operator to be linear. We can achieve this
by introducing a new state
\begin{align}
\dexState := \begin{pmatrix} \dpar & \fwd(\dpar) \end{pmatrix}^\top \in \R^{\Npar + \dimData}.
\end{align}
The observation equation in \ref{inverse_problem_dynamic1} can now be written as 
\begin{align*}
\indexTimeStep[\timeStep+1]{\dataObs} 
&= \begin{pmatrix} 0 & \idMat_{\dimData} \end{pmatrix} \begin{pmatrix} \dpar[\timeStep+1] \\ \fwd(\dpar[\timeStep+1]) \end{pmatrix} + \indexTimeStep[\timeStep+1]{\noise} \\
&= \obsOpLin \dexState[\timeStep+1] + \indexTimeStep[\timeStep+1]{\noise} 
\end{align*}
where we have defined the linear observation operator 
\begin{align}
\obsOpLin := \begin{pmatrix} 0 & \idMat_{\dimData} \end{pmatrix} \in \R^{\dimData \times (\Npar + \dimData)}.
\end{align}
We note that the evolution leaves the $\spar$ portion of the input unchanged, which will imply that the ensemble of $\spar$-particles will 
only be updated during the analysis step of the EnKF, as described below. The complete extended state space
model is thus given by 
\begin{dynamics}
\begin{align}
\dexState[\timeStep+1] &= \mathcal{E}(\dexState[\timeStep]) \label{inverse_problem_dynamic} \\
\indexTimeStep[\timeStep+1]{\dataObs} &= \obsOpLin \dexState[\timeStep+1] + \indexTimeStep[\timeStep+1]{\noise} \nonumber.
\end{align}
\end{dynamics}

The baseline EKI algorithm results from a direct application of the EnKF to the artificial dynamical system \ref{inverse_problem_dynamic}. 
\begin{alg} Ensemble Kalman Inversion \\
\begin{enumerate}
\item \textbf{Initial Ensemble.}  
\item \textbf{Prediction.}
\item \textbf{Analysis.} 
\end{enumerate}
\end{alg}
A more practical algorithm for efficient computation is presented in the appendix. 

% An Improved EKI Formulation
\section{An Improved Formulation of Ensemble Methods for Inverse Problems}
The extended state space formulation suffers from a variety of weaknesses. We now present a unifying perspective which has been developed 
in a series of papers \textbf{cite}. The main idea is to construct a sequence of measures $\postMeas_0, \postMeas_1, \dots$ which converge either 
to the target measure $\postMeas$ or to a Dirac measure centered at a least squares or MAP estimate. In this way, slight variations of the subsequent
setup will either produce sampling or optimization algorithms. 

\subsection{Prior-to-Posterior Map via Likelihood Tempering}
In all cases, the sequence of measures is constructed via a recursion of the form 
\begin{align} 
\postMeas_{\timeStep+1}(d\spar) := \frac{1}{Z_{\timeStep+1}} \exp\left(-h \SSR(\spar) \right) \postMeas_{\timeStep}(d\spar) \label{measure_recursion}
\end{align}
with $Z_{\timeStep}$ denoting the normalizing constant for $\postMeas_{\timeStep}$. In the case where $\postMeas_{\timeStep}$ 
is absolutely continuous with respect to the Lebesgue measure (as is the case 
when the prior is Gaussian) then the updates can be written using the (Lebesgue) densities
\begin{align}
\postDens_{\timeStep+1}(\spar) = \frac{1}{Z_{\timeStep+1}} \exp\left(-\frac{1}{\Ntimestep} \SSR(\spar) \right) \postDens_{\timeStep}(\spar). 
\end{align}
We now discuss how different variations of this setup lead to algorithms either for sampling or optimization. 

\subsubsection{Sampling in Finite Time.} 
We begin by discussing the case whereby the prior measure is transformed into the posterior measure 
in a finite sequence of $\Ntimestep < \infty$ updates. In this case we choose $h := \Ntimestep^{-1}$. 
Iterating the likelihood tempering update, we have that 
\begin{align}
\postMeas_{\Ntimestep}(d\spar) 
&= \frac{1}{\prod_{\timeStep=1}^{\Ntimestep} Z_{\timeStep}} \exp\left(-\sum_{\timeStep=1}^{\Ntimestep} \frac{1}{\Ntimestep} \SSR(\spar)  \right) \priorMeas(d\spar) \nonumber \\
&= \frac{1}{\prod_{\timeStep=1}^{\Ntimestep} Z_{\timeStep}} \exp\left(-\SSR(\spar)  \right) \priorMeas(d\spar) \nonumber \\
&= \postMeas(d\spar),
\end{align}
so indeed the prior is mapped to the posterior in a sequence of $\Ntimestep$ updates. 
Algorithms can thus be developed by applying particle-based filtering algorithms to approximate the mappings $\postMeas_{\timeStep} \mapsto \postMeas_{\timeStep+1}$.  
These algorithms are rigid in the sense that they must be initialized from the prior and iterated for exactly $\Ntimestep$ steps. On the other hand, they benefit from 
avoiding the need for asymptotic convergence convergence, instead converging in finite time. 

\subsubsection{Data Misfit Optimization in Infinite Time.} 
Let us instead consider the choice $h := 1$, so that  
\begin{align} 
\postMeas_{\timeStep}(d\spar) := \frac{1}{Z_{\timeStep+1}} \exp\left(-\timeStep \SSR(\spar) \right) \priorMeas(d\spar).
\end{align}
In this case, the infinite sequence $\{\postMeas_{\timeStep}\}$ will collapse on the minimizer of $\SSR(\spar)$ as $\timeStep \to \infty$, 
restricted to the support of $\priorMeas$; that is, 
\begin{align*}
&\postMeas_{\timeStep}(A) \to \delta_{\spar^\dagger}(A), &&\spar^{\dagger} = \text{argmin}_{\spar \in \text{supp}(\priorMeas)} \SSR(\spar)
\end{align*}
for any Borel set $A \subset \R^{\Npar}$. \textbf{TODO: prove this} In this case, the initial condition is forgotten, so the resulting algorithms 
need not be initialized from the prior. 

\subsubsection{MAP Optimization or Sampling in Infinite Time.} 
We observed in the previous section that the choice of $h = 1$ causes the algorithm 
to collapse on the optimizer of $\SSR(\spar)$. It is natural to wonder if this setting can be modified to 1.) include regularization, and thus 
instead converge to the minimizer of $\SSR_R(\spar)$, or 2.) include carefully designed noise such that $\postMeas_{\timeStep}$ converges
to the posterior $\postMeas$ in infinite time. Based on the previous case, the recursion \ref{measure_recursion} must be modified to include 
information about $\priorMeas$. This will be accomplished via the generalization 
\begin{align} 
\postMeas_{\timeStep+1}(d\spar) = \frac{1}{Z_{\timeStep+1}} \exp\left(-\SSR(\spar) \right) (\postMeas_{\timeStep} P_{\timeStep})(d\spar) \label{measure_recursion_regularized},
\end{align}
where $\{P_{\timeStep}\}$ are suitably chosen Markov kernels. 

\subsection{Designing Artificial Dynamical Systems.}
 In the first EKI derivation, we started by viewing the inverse problem from a dynamical perspective, which implicitly 
defined the sequence of measures $\{\postMeas_{\timeStep}\}$. We now work backwards; having considered different options for such a sequence of measures, we now 
consider designing dynamical systems that realize such sequences. We note that the dynamical system \ref{inverse_problem_dynamic} corresponds to 
either the finite-time formulation with $\Ntimestep=1$ (in which case the initial ensemble must be generated from the prior) or the infinite-time data-misfit optimization 
setting. We will now consider various generalizations of this dynamical formulation that will prove useful for the development of sampling or optimization algorithms. 
The dynamical systems we will consider are defined below. 

\begin{dynamics} (Tikhonov-Phillips optimization, infinite-time) \\
\begin{align}
\dpar[\timeStep+1] &= \alpha \dpar + (1-\alpha)\priorMean + \omega_{\timeStep+1} &&\omega_{\timeStep+1} \sim \Gaussian(0, \CovObs_{\omega}) \\
\ddataObs[\timeStep+1] &= \fwd(\dpar[\timeStep+1]) + \mu_{\timeStep+1} &&\nu_{\timeStep+1} \sim \Gaussian(0, \CovObs_{\nu}), \nonumber
\end{align}
Here $\alpha \in (0, 1]$ is a fixed user-defined parameter, $\priorMean \in \R^{\Npar}$ is the prior mean, and we assume $\spar_0$, $\{\omega_{\timeStep}\}$, $\{\nu_{\timeStep}\}$ are independent. 
\end{dynamics}

We again emphasize that there is a fundamental difference between the finite-time and infinite-time algorithms. The finite-time algorithms are initialized from the prior 
and map the ensemble through a fixed, finite number of time steps to produce approximate samples from the posterior. On the other hand, the infinite-time algorithms, 
which may be used for optimization or sampling, rely on the long-term ergodic behavior of the dynamical systems, and thus the ensemble must be iterated until 
a suitable convergence criterion is reached. 



\end{document} 






