\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{TA Notes}
\author{Andrew Roberts}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction to Stochastic Processes}
\begin{itemize}
\item Discuss the two perspectives on stochastic processes; random function vs. collection of random variables. 
\end{itemize}

\section{Introduction to Markov Chains}

\subsection{Finite State Space}
\textbf{TODO}
\begin{align}
\Prob(X_k = j) = \sum_{i = 1}^{I} \Prob(X_k = j|X_{k - 1} = i)\Prob(X_{k - 1} = i)
\end{align}

Define $P(i, j) = \Prob(X_{k+1} = j|X_k = i)$ and $\mu^{(k)}_j = \Prob(X_k = j)$. This can then be re-written as 
\begin{align}
\mu^{(k)}_j = \sum_{i = 1}^{I} P(i, j) \mu^{(k-1)}_i \label{discrete_transition}
\end{align}

\subsection{General State Space}
If the transition dynamics can be described by probability densities $p(x, \cdot)$ for each $x \in \mathcal{X}$ (where $p(x, y)$ is the density of transitioning from $x$ to $y$) then the 
density $\mu_k$ describing the distribution at time $k$ is given by applying the law of total probability:
\begin{align}
\mu_k(y) = \int p(x, y) \mu_{k-1}(x) dx \label{continuous_transition}
\end{align}
This is the continuous analog of \ref{discrete_transition}. Having to write separate formulas for the discrete and continuous cases is annoying and not amenable to developing a general 
theory. Note that there could also be Markov chains with transitions that are not purely discrete nor continuous, but rather a mixture of the two. The concept of a probability measure allows 
us to write down a general expression that encompasses both \ref{discrete_transition} and \ref{continuous_transition}. 
\begin{align}
\mu_k(A) = \mu_{k - 1}P(A) := \int P(x, A)\mu_{k - 1}(dx) \label{general_transition}
\end{align}
The notation $\mu_{k - 1}P$ is very reminiscent of the left-multiplication of a row vector with the transition matrix in the finite state space case. Matrix multiplication (a linear operation) has 
been replaced with integration (another linear operation), but the basic intuition is the same. 

To be absolutely clear here, let's establish the connection between the general expression \ref{general_transition} and the continuous case densities exist. Recalling that integrating densities over 
a set yields the probability of the set, we have 
\[\Prob(X_k \in A) = \mu_k(A) = \int_A p_k(y) dy\]
The same exact logic applies to the transition probability $P(x, A)$:
\[\Prob(X_k \in A|X_{k - 1} = x) = P(x, A) = \int_A p(x, y) dy \]
Putting these together, \ref{general_transition} becomes,
\[\Prob(X_k \in A) = \int \left[ \int_A p(x, y) dy \right] d\mu_{k-1}(x)\]
Finally we note when densities exist, integrating a function $f(x)$ with respect to the measure $\mu_{k-1}$ can be realized by integrating with respect to the density $p_{k-1}$:
\[\int f(x) \mu_{k-1}(dx) = \int f(x) p_{k-1}(x) dx\]
In our current setting, the function we are integrating is $f(x) = \int_A p(x, y) dy$. Thus, plugging this in we obtain 
\[\Prob(X_k \in A) = \int \left[ \int_A p(x, y) dy \right] d\mu_{k-1}(x) = \int \left[ \int_A p(x, y) dy \right] p_{k-1}(x) dx\]
Note that the outer integral is over the entire state space $\mathcal{X}$. Perhaps a more insightful way to write this is 
\[\Prob(X_k \in A)  = \int_A \int_{\mathcal{X}} p(x, y) p_{k-1}(x) dx dy\]


The concept of an invariant (i.e. stationary) distribution also has a natural generalization. A 
distribution $\mu$ is invariant if $\mu P = \mu$; that is, if the distribution is unchanged one time step in the future (and hence unchanged for all future times). By plugging in 
\ref{general_transition}, we see that $\mu P = \mu$ is really shorthand for 
\begin{align*}
\mu(A) = \int P(x, A) \mu(dx) \text{ for all } A \in \mathcal{F}
\end{align*}
Note that the ``for all $A \in \mathcal{F}$'' is essential; for the two distributions $\mu$ and $\mu P$ to be equal they must assign the same probability to every set $A$. 

\subsection{Questions}
\begin{itemize}
\item Should the probability in example 3.4 be divided by $\Prob(X_{k-1} = x_{k-1})$? Or rather the density $f_{X_{k-1}}(x_{k-1})$? 
\end{itemize}



% SDEs
\section{Continuous Time}
\begin{itemize}
\item Motivate as follows: we can move from non-random discrete dynamical systems (e.g. difference equations) to things like Markov Chains by introducing randomness. We can do the 
same to move from continuous-time dynamical systems (e.g. ODEs) to continuous-time stochastic dynamical systems (SDEs) 
\item Include discussion of random vs stochastic DEs (see Staurt)
\end{itemize}






\end{document}




