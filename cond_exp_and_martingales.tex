\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Conditional Expectation and Martingales}
\author{Andrew Roberts}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Defining Conditional Expectation}
Here we slowly build up to the general definition of conditional expectation in order to gain intuition. 

\subsection{A Simple Example}

\subsubsection{Constructing the Probability Space for a Two-Coin Flip Experiment}
We begin with the simple example of independently flipping two coins, with respective probabilities $p$ and $q$ of landing heads. Coding $0$ as tails and $1$ as heads, the probability space associated with 
this experiment is
\[\Omega = \{(0, 0), (0, 1), (1, 0), (1, 1)\}\]
The typical $\sigma$-algebra to consider here is the full power set 
\[\mathcal{F} = 2^{\Omega} = \{\text{All subsets of } \Omega\}\]
Writing out all of the subsets would be inconvenient, but note that there are $2^4 = 16$ sets in the collection $2^{\Omega}$. Now that we have the measurable space $(\Omega, \mathcal{F})$, we can 
define a probability measure $\mathbb{P}: \mathcal{F} \to [0, 1]$, which assigns weights to each set in the $\sigma$-algebra. The probability measure corresponding to the two-coin experiment is 
\begin{align*}
\Prob(\{(1, 1)\}) &= pq \\
\Prob(\{(0, 0)\}) &= (1 - p)(1 - q) \\
\Prob(\{(0, 1)\}) &= (1 - p)q \\
\Prob(\{(1, 0)\}) &= p(1 - q)
\end{align*}
This follows from the fact that any sequence of two independent flips has probability equal to the product of the probabilities of the individual flips. 
For example, the probability of flipping two heads in a row should be the product of each independently turning up heads. 
In this case, defining $\Prob(\{\omega\})$ for all singleton sets $\{\omega\} \in \mathcal{F}$ is sufficient to define $\Prob$ on all of $\mathcal{F}$, since the probabilities of disjoint events must add. 
For example, consider 
\[A = \{(0, 0), (0, 1)\} = \{\text{First flip is tails and second flip is heads or tails}\}\]
The probability of $A$ is then sum of the probabilities of the disjoint singleton sets $\{(0, 0)\}$ and 
$\{0, 1\}$. 
\[\Prob(A) = \Prob(\{\omega \in \Omega: \omega \in \{(0, 0), (0, 1)\}\}) = \Prob(\{(0, 0)\}) + \Prob(\{(0, 1)\}) = (1 - p)(1 - q) + (1 - p)q = 1 - p\] 
We have thus constructed a valid probability space $(\Omega, \mathcal{F}, \Prob)$. 

\subsubsection{A Smaller $\sigma$-algebra}
Although the power set $\sigma$-algebra is the natural choice here, for the purposes of illustration let's consider an alternative 
$\sigma$-algebra. Since $\sigma$-algebras are supposed to model \textit{knowledge} or \textit{information}, let's try to define the $\sigma$-algebra $\mathcal{G}$ that models the knowledge of the the total number 
of heads in the experiment. Intuitively, this is less information than is captured by $\mathcal{F}$. For example., the power set $\sigma$-algebra allowed us to make statements about the probability of sets $\{0, 1\}$ and 
$\{1, 0\}$. However, each of these sets have the same number of heads (one), so according to $\mathcal{G}$ we should not be able to distinguish between these two events. $\mathcal{G}$ should allow us to make statements 
about the probability of events like ``the experiment produced one head'' but it should not let us say anything about which coin produced that head. Therefore, the sets that have the same number of heads
\[\{(0, 0)\}, \{(0, 1), (1, 0)\}, \{(1, 1)\}\] 
should be in $\mathcal{G}$. The $\sigma$-algebra can now be completed by considering unions, intersections, and complements of these sets.
\begin{align*}
\mathcal{G} = &\{\{(0, 0)\}, \{(0, 1), (1, 0)\}, \{(1, 1)\}, \\
		       &\{(0, 0), (0, 1), (1, 0)\}, \{(1, 1), (0, 1), (1, 0)\}, \{(0, 0), (1, 1)\} \}
\end{align*}
If should make intuitive sense that these are the sets we end up with; e.g. $\{(0, 0), (0, 1), (1, 0)\}$ is the set corresponding to the event ``the experiment produced zero or one heads''. None of these sets will allow us to make 
probabilistic statements about the specific sequence in which the heads appeared in the coin flips. We can again define a probability measure $\Prob: \mathcal{G} \to [0, 1]$ (I am using the same notation $\Prob$ but note that 
this is a different function than before; it is not even defined on the same domain) on the measurable space $(\Omega, \mathcal{G})$. 
\begin{align*}
\Prob(\{(1, 1)\}) &= pq \\
\Prob(\{(0, 0)\}) &= (1 - p)(1 - q) \\
\Prob(\{(0, 1), (1, 0)\}) &= p(1 - q) + (1 - p)q
\end{align*}
The probability $p(1 - q) + (1 - p)q$ is simply the probability of flipping a single head (either the first is heads and the second is tails, or vice versa). 
The main point about $\mathcal{G}$ is that the sets $\{(0, 1)\}$ and $\{1, 0\}$ are indistinguishable. Notice that the probability measure assigns a probability to $\{(0, 1), (1, 0)\}$ by averaging over the probabilities 
of $\{(0, 1)\}$ and $\{(0, 1)\}$, but it cannot assign probabilities to these latter two sets! 

\subsubsection{Smaller $\sigma$-algebra generated by a random variable}
In the previous section, we stated the goal of defining a $\sigma$-algebra $\mathcal{G}$ that captured knowledge only of the number of heads that resulted from the experiment. We can arrive at the same $\sigma$-algebra by 
considering the random variable $Y: \Omega \to \{0, 1, 2\}$ that returns the number of heads in the experiment; e.g. $Y((1, 1)) = 2$ and $Y(0, 1) = 1$. My claim is that $\mathcal{G}$ is the smallest $\sigma$-algebra to which $Y$
is measurable. Intuitively, this should be the case since being able to make probabilistic statements about the values $Y$ can assume only requires knowledge about how many heads occurred in the experiment. Let's show this more formally. $Y$ can assume three values, and hence we need to consider the inverse image of these three values. 
\begin{align*}
Y^{-1}(0) &= \{(0, 0)\} \\
Y^{-1}(1) &= \{(1, 0), (0, 1)\} \\
Y^{-1}(2) &= \{(1, 1)\}
\end{align*}
So the three sets on the righthand side are the three subsets of $\Omega$ to which we must assign probabilities in order to define a distribution on $Y$. This is the minimal collection of sets with this property, so the minimal 
$\sigma$-algebra follows from taking unions, intersections, and complements of these sets. But this is the same exact thing we did previously to arrive at $\mathcal{G}$! Thus, we have shown that 
\[\mathcal{G} = \sigma(Y)\]
or in words: $\mathcal{G}$ is the $\sigma$-algebra generated by $Y$. This just means that $\mathcal{G}$ is the smallest possible $\sigma$-algebra to which $Y$ is measurable. The smallest $\sigma$-algebra can also be 
thought of as the ``coarsest'' in that it contains less fine-grained information compared to, for example, $\mathcal{F}$. $Y$ is also measurable with respect to $\mathcal{F}$, but $\mathcal{F}$ contains more sets than are needed 
to define a distribution on $Y$. Note also that \textit{any} random variable $X: \mathcal{\Omega} \to \R$ that is measurable with respect to $\mathcal{G}$ must have the property $X((1, 0)) = X((0, 1))$. This is because $\mathcal{G}$
does not contain enough information to differentiate between the two outcomes $(1, 0)$ and $(0, 1)$. 

\subsubsection{Defining conditional expectation with respect to the smaller $\sigma$-algebra}
We are now ready to give a definition of conditional expectation in this simple setting. In this setting and the more general one, conditional expectation is defined as conditional with respect to a $\sigma$-algebra. This makes sense given the fact that $\sigma$-algebra models knowledge, so we seek to define an expectation with respect to knowledge of certain events. Let $X: \Omega \to \R$ be any random variable that is $\mathcal{F}$ measurable. 
The conditional expectation of $X$ given $\mathcal{G}$ will itself be a random variable, let's call it $Z$. Intuitively, if we condition on $\mathcal{G}$ then we are assuming knowledge of only the events in $\mathcal{G}$. Given 
these events, the conditional expectation $Z$ will give the ``best guess'' of $X$ for each event in $\mathcal{G}$. Thus, $Z$ must be $\mathcal{G}$ measurable but does not in general need to be $\mathcal{F}$ measurable. 
We can think of $Z(\omega)$ in the following way: 
\begin{itemize}
\item The random experiment produces an outcome $\omega \in \Omega$. 
\item We only have knowledge of which set in $\mathcal{G}$ that $\omega$ falls into. Suppose $\omega \in G$ for some $G \in \mathcal{G}$. 
\item $Z(\omega)$ averages over the $\mathcal{F}$-information in $G$ to give the best guess of $X$. 
\end{itemize}
To make this more clear, we first present an example. After I will give the definition of the conditional expectation of $X$ given $\mathcal{G}$ in this setting. For now, consider 
$X = \mathbbm{1}\{\text{Second flip is heads}\}$. So we want to condition the random variable representing knowledge that the second flip is heads on knowledge of the total number of heads.
If we know there are zero heads, then our best guess (and the correct one) at the value of $X$ is $0$. Similarly, if we know there are two heads then we can correctly infer that $X = 1$. However, 
if we know there is a single head, then we are not able to pin down the exact value of $X$. So instead $Z$ averages over the two possibilities: that either the first flip or the second flip contributed the 
single head. Thus, we define $Z(\omega) := $
\begin{align*}
&0, \text{ if } \omega \in \{(0, 0)\} \\
&1, \text{ if } \omega \in \{(1, 1)\} \\
&q \cdot 1 + p \cdot 0, \text{ if } \omega \in \{(1, 0), (0, 1)\}
\end{align*}

\subsubsection{What does it mean to condition on a random variable?}
We have given a rigorous (though currently very limited) definition of conditional expectation with respect to a $\sigma$-algebra $\mathcal{G}$. How does this relate to the usual convention of writing conditional 
expectations with respect to random variables? For example, consider $Y$, the number of heads in the experiment. What does $\E[X|Y]$ mean? When we use this notation, the true rigorous meaning underlying it 
is 
\[\E[X|Y] := \E[X|\sigma(Y)],\]
namely, that we condition with respect to the $\sigma$-algebra generated by the random variable. In the case of this example, we know that $\mathcal{G} = \sigma(Y)$ so $\E[X|Y]$ is in fact the conditional expectation 
we have been working with throughout this example!


\end{document}


